{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97258,"sourceType":"competition"},{"sourceId":11330888,"sourceType":"datasetVersion","datasetId":7088011}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# EmergencyZIP AI","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T01:51:51.500216Z","iopub.execute_input":"2025-04-06T01:51:51.500602Z","iopub.status.idle":"2025-04-06T01:51:52.637567Z","shell.execute_reply.started":"2025-04-06T01:51:51.500561Z","shell.execute_reply":"2025-04-06T01:51:52.636559Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip uninstall -qqy jupyterlab  # Remove unused packages from Kaggle's base image that conflict\n!pip install -U -q \"google-genai==1.7.0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T23:46:54.497876Z","iopub.execute_input":"2025-04-05T23:46:54.498193Z","iopub.status.idle":"2025-04-05T23:47:03.993202Z","shell.execute_reply.started":"2025-04-05T23:46:54.498166Z","shell.execute_reply":"2025-04-05T23:47:03.991134Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\n\nfrom IPython.display import HTML, Markdown, display","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T23:47:06.408202Z","iopub.execute_input":"2025-04-05T23:47:06.408579Z","iopub.status.idle":"2025-04-05T23:47:08.181318Z","shell.execute_reply.started":"2025-04-05T23:47:06.408548Z","shell.execute_reply":"2025-04-05T23:47:08.180171Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google.api_core import retry\n\n\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\ngenai.models.Models.generate_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.generate_content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T23:47:09.690189Z","iopub.execute_input":"2025-04-05T23:47:09.691138Z","iopub.status.idle":"2025-04-05T23:47:09.962541Z","shell.execute_reply.started":"2025-04-05T23:47:09.691096Z","shell.execute_reply":"2025-04-05T23:47:09.961301Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T23:47:12.835349Z","iopub.execute_input":"2025-04-05T23:47:12.835946Z","iopub.status.idle":"2025-04-05T23:47:12.919564Z","shell.execute_reply.started":"2025-04-05T23:47:12.835907Z","shell.execute_reply":"2025-04-05T23:47:12.918344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"client = genai.Client(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T23:47:15.177960Z","iopub.execute_input":"2025-04-05T23:47:15.178350Z","iopub.status.idle":"2025-04-05T23:47:15.616971Z","shell.execute_reply.started":"2025-04-05T23:47:15.178316Z","shell.execute_reply":"2025-04-05T23:47:15.615680Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# When using as interactive AI, uncomment this whole section\n\"\"\"\nmedical_emergency = input(\"Hello, what medical emergency are you dealing with?\")\nzipcode = int(input(\"What zipcode are you currently living now?\"))\n\nmedical_request = {\n    'Zipcode': zipcode, \n    'Medical Emergency': medical_emergency\n}\nmedical_request_str = str(medical_request)\nmedical_request_str\n\"\"\"\n\n# When saving to GitHub, uncomment this whole section \nmedical_emergency = 'broken arm'\nzipcode = 77035\n\nmedical_request = {\n    'Zipcode': zipcode, \n    'Medical Emergency': medical_emergency\n}\nmedical_request_str = str(medical_request)\nmedical_request_str","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T23:47:17.947162Z","iopub.execute_input":"2025-04-05T23:47:17.947538Z","iopub.status.idle":"2025-04-05T23:47:38.063194Z","shell.execute_reply.started":"2025-04-05T23:47:17.947464Z","shell.execute_reply":"2025-04-05T23:47:38.062007Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import typing_extensions as typing\n\nclass MedicalRequest(typing.TypedDict): \n    zipcode: int\n    medical_emergency: str\n\njson_response = client.models.generate_content(\n    model='gemini-2.0-flash', \n    config=types.GenerateContentConfig(\n        temperature=0.1, \n        response_mime_type=\"application/json\", \n        response_schema=MedicalRequest\n    ), \n    contents=medical_request_str\n)\n\njson_form = json_response.text\n\nprint(json_form)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T23:47:41.211353Z","iopub.execute_input":"2025-04-05T23:47:41.211722Z","iopub.status.idle":"2025-04-05T23:47:41.914738Z","shell.execute_reply.started":"2025-04-05T23:47:41.211691Z","shell.execute_reply":"2025-04-05T23:47:41.913564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"few_shot_prompt = \"\"\"Parse JSON into a string request and only return output: \n\nEXAMPLE: \n{\n\"zipcode\": 78664, \n\"medical_emergency\": \"heart attack\" \n}\n\"Patient currently living in zipcode 78664 wants to seek medical attention for heart attack.\"\n\nEXAMPLE: \n{\n\"zipcode\": 77055, \n\"medical_emergency\": \"broken leg\" \n}\n\"Patient currently living in zipcode 77055 wants to seek medical attention for broken leg.\"\n\nEXAMPLE: \n{\n\"zipcode\": 78681, \n\"medical_emergency\": \"dog bite\" \n}\n\"Patient currently living in zipcode 78681 wants to seek medical attention for dog bite.\"\n\"\"\"\n\nmodel_config = types.GenerateContentConfig(\n    temperature=0.1, \n    top_p=1, \n    max_output_tokens=500\n)\n\nfew_shot_response = client.models.generate_content(\n    model='gemini-2.0-flash', \n    config=model_config,\n    contents=[few_shot_prompt, json_form]\n)\n\nstr_request = few_shot_response.text\nprint(str_request)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T23:47:44.937938Z","iopub.execute_input":"2025-04-05T23:47:44.938253Z","iopub.status.idle":"2025-04-05T23:47:45.356293Z","shell.execute_reply.started":"2025-04-05T23:47:44.938228Z","shell.execute_reply":"2025-04-05T23:47:45.355344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt_config = types.GenerateContentConfig(\n    temperature=0.1, \n    top_p=1.0, \n    max_output_tokens=250\n)\n\ngenerate_prompt_prompt = \"Generate precise prompt that asks for nearest medical centers for this request: \" + str_request\n\nprompt_response = client.models.generate_content(\n    model='gemini-2.0-flash', \n    config=prompt_config, \n    contents= generate_prompt_prompt\n)\n\nprompt = prompt_response.text\nprint(prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T23:47:48.891589Z","iopub.execute_input":"2025-04-05T23:47:48.891954Z","iopub.status.idle":"2025-04-05T23:47:49.731243Z","shell.execute_reply.started":"2025-04-05T23:47:48.891925Z","shell.execute_reply":"2025-04-05T23:47:49.730079Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"config_with_search = types.GenerateContentConfig(\n    tools=[types.Tool(google_search=types.GoogleSearch())],\n)\n\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash', \n    contents=prompt, \n    config=config_with_search,\n)\n\nrc = response.candidates[0]\n\nMarkdown(rc.content.parts[0].text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T23:47:52.168350Z","iopub.execute_input":"2025-04-05T23:47:52.168759Z","iopub.status.idle":"2025-04-05T23:47:58.574974Z","shell.execute_reply.started":"2025-04-05T23:47:52.168727Z","shell.execute_reply":"2025-04-05T23:47:58.573860Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}