{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3414462e",
   "metadata": {
    "papermill": {
     "duration": 0.010099,
     "end_time": "2025-04-20T21:15:12.240154",
     "exception": false,
     "start_time": "2025-04-20T21:15:12.230055",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EmergencyZIP AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e58df6",
   "metadata": {
    "papermill": {
     "duration": 0.006708,
     "end_time": "2025-04-20T21:15:12.255098",
     "exception": false,
     "start_time": "2025-04-20T21:15:12.248390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Intro\n",
    "\n",
    "As a Data Scientist in Healthcare with over two years of industry experience, I’ve learned that a person’s zip code (postal code) plays a crucial role in determining their health status. Where an individual lives can significantly impact their overall health, as local healthcare quality varies across regions. Unfortunately, many people are unaware of the healthcare facilities available in their area or may not know which one is best suited for their specific medical needs. To address this, I developed EmergencyZIP AI, a tool designed to help individuals identify the best medical facilities based on their symptoms or conditions, while considering their zip code as a critical factor in their health status.\n",
    "\n",
    "## Use Case and Solution Approach\n",
    "\n",
    "Individuals often seek clarity about the illness or medical condition they may be experiencing and want to know which nearby healthcare facilities can provide the best treatment. EmergencyZIP AI utilizes advanced AI to not only help individuals identify the potential illness or condition they’re facing but also guide them to the most appropriate medical facilities nearby based on zip code.\n",
    "\n",
    "The system takes zip codes into account, recognizing the importance of location in determining healthcare accessibility and quality.\n",
    "\n",
    "## Innovation/Novelty\n",
    "\n",
    "Although the internet provides many resources for finding local healthcare facilities, searching through numerous results can be overwhelming. Moreover, it’s difficult for individuals to accurately diagnose their condition without medical expertise. EmergencyZIP AI solves this by offering personalized and tailored responses, focusing specifically on the individual’s symptoms and their location.\n",
    "\n",
    "While human doctors are skilled at diagnosing, they may still be influenced by biases or errors. AI, on the other hand, minimizes these biases by considering the patient’s demographic information. However, I acknowledge that human doctors can recognize nuances that AI may miss, as AI is typically trained on generalized data. The goal of EmergencyZIP AI is to make medical information more accessible and less overwhelming for users, while providing individualized insights.\n",
    "\n",
    "## Process\n",
    "\n",
    "EmergencyZIP AI operates using Structured Output/JSON Mode/Controlled Generation, Few-Shot Prompting, and Grounding techniques. Here’s how it works:\n",
    "\n",
    "1. JSON Mode: The AI processes the patient’s demographic information and current symptoms, converting it into a structured JSON format, similar to a simplified patient intake form.\n",
    "2. Few-Shot Prompting: The AI generates a request based on the information provided by the JSON form using a few provided examples to maintain consistency and accuracy which is then included in a prompt for the AI asking for the most relevant data to help diagnose the condition. The AI also extracts zipcode from the JSON form using a few provided examples to maintain accuracy to be used to find nearby locations.\n",
    "3. Grounding: Using the provided information, the AI offers the most accurate potential diagnosis for the individual’s symptoms. Then, it uses the zip code to find the nearest and most appropriate medical facilities for treatment. Then, the AI provides payment and insurance plan information for each recommended location.\n",
    "4. Controlled Generation: As the AI is responsible for providing the most accurate and thorough information as possible, we try to keep the temperature (degree of randomness of output) parameter as low as possible while the top-p (the maximum cumulative probability that the model can reach to select tokens as candidates) parameter as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d39dfb",
   "metadata": {
    "papermill": {
     "duration": 0.00643,
     "end_time": "2025-04-20T21:15:12.268335",
     "exception": false,
     "start_time": "2025-04-20T21:15:12.261905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Importing Relevant Libraries and Technologies \n",
    "\n",
    "I set up Gemini API to implement my AI (the code also retrieves the API Key from Kaggle Secrets to retrieve the Google API that makes it possible for the AI to work) and imported the Pandas and Random libraries (and other unnamed libraries) to do my test run to check if the AI works as intended or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f1cc213",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-20T21:15:12.283502Z",
     "iopub.status.busy": "2025-04-20T21:15:12.283095Z",
     "iopub.status.idle": "2025-04-20T21:15:13.354774Z",
     "shell.execute_reply": "2025-04-20T21:15:13.353590Z"
    },
    "papermill": {
     "duration": 1.081394,
     "end_time": "2025-04-20T21:15:13.356519",
     "exception": false,
     "start_time": "2025-04-20T21:15:12.275125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/patient-symptom-dataset/patient_symptom_data_with_demographics_imperial.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bf71fc",
   "metadata": {
    "papermill": {
     "duration": 0.006686,
     "end_time": "2025-04-20T21:15:13.370389",
     "exception": false,
     "start_time": "2025-04-20T21:15:13.363703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The cell below removes any irrelevant libraries that may conflict with the Google Generative AI capabilities and install the Google Gemini Generative AI package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85691c92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T21:15:13.386200Z",
     "iopub.status.busy": "2025-04-20T21:15:13.385474Z",
     "iopub.status.idle": "2025-04-20T21:15:22.742184Z",
     "shell.execute_reply": "2025-04-20T21:15:22.740862Z"
    },
    "papermill": {
     "duration": 9.366912,
     "end_time": "2025-04-20T21:15:22.744278",
     "exception": false,
     "start_time": "2025-04-20T21:15:13.377366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip uninstall -qqy jupyterlab  # Remove unused packages from Kaggle's base image that conflict\n",
    "!pip install -U -q \"google-genai==1.7.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b5b154",
   "metadata": {
    "papermill": {
     "duration": 0.007167,
     "end_time": "2025-04-20T21:15:22.758873",
     "exception": false,
     "start_time": "2025-04-20T21:15:22.751706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Install all relevant libraries for the Google Generative AI capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9976b861",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T21:15:22.775152Z",
     "iopub.status.busy": "2025-04-20T21:15:22.774789Z",
     "iopub.status.idle": "2025-04-20T21:15:24.174102Z",
     "shell.execute_reply": "2025-04-20T21:15:24.172922Z"
    },
    "papermill": {
     "duration": 1.409822,
     "end_time": "2025-04-20T21:15:24.176224",
     "exception": false,
     "start_time": "2025-04-20T21:15:22.766402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "from IPython.display import HTML, Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08cd3e76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T21:15:24.192485Z",
     "iopub.status.busy": "2025-04-20T21:15:24.191901Z",
     "iopub.status.idle": "2025-04-20T21:15:24.451976Z",
     "shell.execute_reply": "2025-04-20T21:15:24.450880Z"
    },
    "papermill": {
     "duration": 0.270347,
     "end_time": "2025-04-20T21:15:24.454036",
     "exception": false,
     "start_time": "2025-04-20T21:15:24.183689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "\n",
    "\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "genai.models.Models.generate_content = retry.Retry(\n",
    "    predicate=is_retriable)(genai.models.Models.generate_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5be6809",
   "metadata": {
    "papermill": {
     "duration": 0.006997,
     "end_time": "2025-04-20T21:15:24.468598",
     "exception": false,
     "start_time": "2025-04-20T21:15:24.461601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Retrieve the Google API Key from Kaggle Secrets to make possible for the AI to work in this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42a9f3bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T21:15:24.485666Z",
     "iopub.status.busy": "2025-04-20T21:15:24.485061Z",
     "iopub.status.idle": "2025-04-20T21:15:24.981826Z",
     "shell.execute_reply": "2025-04-20T21:15:24.980507Z"
    },
    "papermill": {
     "duration": 0.507229,
     "end_time": "2025-04-20T21:15:24.984117",
     "exception": false,
     "start_time": "2025-04-20T21:15:24.476888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a312a7db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T21:15:25.001437Z",
     "iopub.status.busy": "2025-04-20T21:15:25.001015Z",
     "iopub.status.idle": "2025-04-20T21:15:25.384860Z",
     "shell.execute_reply": "2025-04-20T21:15:25.383764Z"
    },
    "papermill": {
     "duration": 0.394337,
     "end_time": "2025-04-20T21:15:25.386802",
     "exception": false,
     "start_time": "2025-04-20T21:15:24.992465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86002686",
   "metadata": {
    "papermill": {
     "duration": 0.007164,
     "end_time": "2025-04-20T21:15:25.401223",
     "exception": false,
     "start_time": "2025-04-20T21:15:25.394059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generative AI Capabilities Used and Reasoning \n",
    "\n",
    "These are the 3 Generative AI Capabilities Used in this AI and why they are used in this AI: \n",
    "* **Structured Output/JSON Mode/Controlled Generation**: For JSON Mode, I want to somewhat mimic the forms that patients fill out when they are requesting care from a medical facility, but simplier and more abstract. For Structured Output and Controlled Generation, I want my responses to be as accurate and precise as possible where creativity may not be required but accuracy is definitely required to get the best responses as possible.\n",
    "* **Few-Shot Prompting**: First of all, I want to create requests for the AI to know who it is providing information for, but I want the formatting of the requests to be as consistent as possible so that the information does not get muddled up which would make things more difficult for the AI to process and provide information for. Then, I also want to extract the zipcode from the JSON form, but sometimes the AI can hallucinate and return irrelevant or incorrect information, so I want the let the AI know how to return the zipcode correctly.\n",
    "* **Grounding**: This is the central capability of the AI since the AI is responsible for finding all the relevant possible nearest locations to the patient based on postal code/zipcode. Since we are exploring so many zipcodes and it is possible that the AI does not know every zipcode or medical facilities per zipcode, we need to rely on external sources to get the best answers possible. However, since we don't have a document listing out every medical facility per zipcode or all zipcodes, we would need to rely on the internet to give us answers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c9ef33",
   "metadata": {
    "papermill": {
     "duration": 0.006967,
     "end_time": "2025-04-20T21:15:25.415835",
     "exception": false,
     "start_time": "2025-04-20T21:15:25.408868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generative AI Capability #1: Structured Output/JSON Mode/Controlled Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139f4766",
   "metadata": {
    "papermill": {
     "duration": 0.007211,
     "end_time": "2025-04-20T21:15:25.430081",
     "exception": false,
     "start_time": "2025-04-20T21:15:25.422870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### JSON Mode\n",
    "\n",
    "I created a Python class, MedicalPatient, to format a simple and abstract patient form in JSON. Then, I developed a get_json_form function that takes an entry (in the test run that I did to test my AI, a row from a Pandas DataFrame) and structures it into the JSON format defined in the MedicalPatient class.\n",
    "\n",
    "##### get_json_form function: \n",
    "\n",
    "**Description**: Function takes in an entry (in this case, a Pandas dataframe row) and structures the information provided into a formalized JSON form as structured in the MedicalPatients class. \n",
    "\n",
    "**Input**: ***patient_symptom_entry***: Dataframe Pandas row (for now) of all information needed to be processed as JSON form \n",
    "\n",
    "**Output**: ***json_form***: String of formalized JSON form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff04b137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T21:15:25.445755Z",
     "iopub.status.busy": "2025-04-20T21:15:25.445406Z",
     "iopub.status.idle": "2025-04-20T21:15:25.451640Z",
     "shell.execute_reply": "2025-04-20T21:15:25.450554Z"
    },
    "papermill": {
     "duration": 0.016046,
     "end_time": "2025-04-20T21:15:25.453326",
     "exception": false,
     "start_time": "2025-04-20T21:15:25.437280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import typing_extensions as typing\n",
    "\n",
    "class MedicalPatient(typing.TypedDict): \n",
    "    zipcode: int\n",
    "    age: int\n",
    "    gender: str\n",
    "    race: str\n",
    "    ethnicity: str\n",
    "    height: float\n",
    "    weight: float\n",
    "    symptoms: list[str]\n",
    "\n",
    "def get_json_form(patient_symptom_entry): \n",
    "    entry_str = patient_symptom_entry.to_string()\n",
    "    json_response = client.models.generate_content(\n",
    "        model='gemini-2.0-flash', \n",
    "        config=types.GenerateContentConfig(\n",
    "            temperature=0.1, \n",
    "            response_mime_type=\"application/json\", \n",
    "            response_schema=MedicalPatient\n",
    "        ), \n",
    "        contents=entry_str\n",
    "    )\n",
    "    json_form = json_response.text\n",
    "    return json_form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd74106d",
   "metadata": {
    "papermill": {
     "duration": 0.0072,
     "end_time": "2025-04-20T21:15:25.468193",
     "exception": false,
     "start_time": "2025-04-20T21:15:25.460993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Structured Output/Controlled Generation\n",
    "\n",
    "**Description**: I created the get_general_model_config function to return a Gemini-generated output based on the temperature, top_p, and maximum number of tokens to return inputs.\n",
    "\n",
    "**Input**: \n",
    "* ***temperature***: double that reflects the degree of randomness in selecting tokens for output\n",
    "* ***top_p***: double that is the maximum culmulative probability that the model can reach to select tokens as candidates\n",
    "* ***max_output_tokens***: int that indicates the maximum number of tokens that should be provided and included in the input\n",
    "\n",
    "**Output**: ***str_output***: String of Gemini-generated output based on input parameters provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94c84fe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T21:15:25.485463Z",
     "iopub.status.busy": "2025-04-20T21:15:25.485080Z",
     "iopub.status.idle": "2025-04-20T21:15:25.489641Z",
     "shell.execute_reply": "2025-04-20T21:15:25.488487Z"
    },
    "papermill": {
     "duration": 0.015135,
     "end_time": "2025-04-20T21:15:25.491461",
     "exception": false,
     "start_time": "2025-04-20T21:15:25.476326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_general_model_config(temperature, top_p, max_output_tokens): \n",
    "    str_output = types.GenerateContentConfig(\n",
    "        temperature=temperature, \n",
    "        top_p=top_p, \n",
    "        max_output_tokens=max_output_tokens\n",
    "    )\n",
    "    return str_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a95961",
   "metadata": {
    "papermill": {
     "duration": 0.00726,
     "end_time": "2025-04-20T21:15:25.506223",
     "exception": false,
     "start_time": "2025-04-20T21:15:25.498963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generative AI Capability #2: Few-Shot Prompting\n",
    "\n",
    "**Description**: I created the few_shot_func function to implement the few-shot prompting AI capability as code\n",
    "\n",
    "**Input**: \n",
    "* ***model_input***: String that is the input (e.g. a JSON form) that the model takes in consideration of to provide an output response\n",
    "* ***prompt***: String that is the input prompt to provide to the Gemini model to provide a response for; in few-shot prompting, the input prompt provides a few examples with their expected responses to the Gemini model so that the Gemini models knows what to produce for their output format-wise and what their output should look like\n",
    "* ***config***: Python method that is configuration to be used for the Gemini model to produce output (*refer to get_general_model_config as example of Python method to use as possible parameter value*)\n",
    "\n",
    "**Output**: ***str_output***: String of Gemini-generated output based on input parameters provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a553757f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T21:15:25.521910Z",
     "iopub.status.busy": "2025-04-20T21:15:25.521542Z",
     "iopub.status.idle": "2025-04-20T21:15:25.526515Z",
     "shell.execute_reply": "2025-04-20T21:15:25.525384Z"
    },
    "papermill": {
     "duration": 0.014899,
     "end_time": "2025-04-20T21:15:25.528465",
     "exception": false,
     "start_time": "2025-04-20T21:15:25.513566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def few_shot_func(model_input, prompt, config): \n",
    "    few_shot_response = client.models.generate_content(\n",
    "        model='gemini-2.0-flash', \n",
    "        config=config,\n",
    "        contents=[prompt, model_input]\n",
    "    )\n",
    "    str_response = few_shot_response.text\n",
    "    return str_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e97ee6",
   "metadata": {
    "papermill": {
     "duration": 0.007586,
     "end_time": "2025-04-20T21:15:25.543740",
     "exception": false,
     "start_time": "2025-04-20T21:15:25.536154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generative AI Capability #3: Grounding\n",
    "\n",
    "**Description**: I created the grounding_func function to implement the grounding AI capability as code\n",
    "\n",
    "**Input**: ***input_prompt***: String that is the input prompt to provide to the Gemini model to provide a response for\n",
    "\n",
    "**Output**: ***str_response***: String that is the output provided by the Gemini model as response to the input prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a38fb57b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T21:15:25.559706Z",
     "iopub.status.busy": "2025-04-20T21:15:25.559314Z",
     "iopub.status.idle": "2025-04-20T21:15:25.564705Z",
     "shell.execute_reply": "2025-04-20T21:15:25.563431Z"
    },
    "papermill": {
     "duration": 0.015396,
     "end_time": "2025-04-20T21:15:25.566456",
     "exception": false,
     "start_time": "2025-04-20T21:15:25.551060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grounding_func(input_prompt): \n",
    "    config_with_search = types.GenerateContentConfig(\n",
    "        tools=[types.Tool(google_search=types.GoogleSearch())],\n",
    "    )\n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-2.0-flash', \n",
    "        contents=input_prompt, \n",
    "        config=config_with_search,\n",
    "    )\n",
    "    rc = response.candidates[0]\n",
    "    str_response = rc.content.parts[0].text\n",
    "    return str_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55206362",
   "metadata": {
    "papermill": {
     "duration": 0.007383,
     "end_time": "2025-04-20T21:15:25.581963",
     "exception": false,
     "start_time": "2025-04-20T21:15:25.574580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## EmergencyZIP AI Test Run\n",
    "\n",
    "Kaggle Notebooks seem to not work or do well with Python input, so instead, we generated a dataset of patients with relevant demographic information and their symptoms through ChatGPT (so the dataset below is ChatGPT-generated), and then the code picks a random patient to test run the AI to make sure it actually works as intended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5034459",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T21:15:25.598191Z",
     "iopub.status.busy": "2025-04-20T21:15:25.597852Z",
     "iopub.status.idle": "2025-04-20T21:15:25.652571Z",
     "shell.execute_reply": "2025-04-20T21:15:25.651332Z"
    },
    "papermill": {
     "duration": 0.065323,
     "end_time": "2025-04-20T21:15:25.654711",
     "exception": false,
     "start_time": "2025-04-20T21:15:25.589388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Race</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Height_in</th>\n",
       "      <th>Weight_lb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>70112</td>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>Joint pain;Runny nose;Loss of taste;Sore throat</td>\n",
       "      <td>Other</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>73.6</td>\n",
       "      <td>229.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>90002</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>Joint pain;Muscle ache;Dry cough</td>\n",
       "      <td>White</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>76.8</td>\n",
       "      <td>262.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P003</td>\n",
       "      <td>20001</td>\n",
       "      <td>46</td>\n",
       "      <td>Male</td>\n",
       "      <td>Chest tightness;Sneezing;Fever;Breathing diffi...</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>67.3</td>\n",
       "      <td>187.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P004</td>\n",
       "      <td>73301</td>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>Fatigue;Abdominal pain</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>67.7</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P005</td>\n",
       "      <td>96813</td>\n",
       "      <td>23</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>Rash;Sore throat;Loss of smell;Abdominal pain;...</td>\n",
       "      <td>Pacific Islander</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>74.8</td>\n",
       "      <td>211.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>P096</td>\n",
       "      <td>55414</td>\n",
       "      <td>80</td>\n",
       "      <td>Female</td>\n",
       "      <td>Blurred vision;Dry cough</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>66.5</td>\n",
       "      <td>264.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>P097</td>\n",
       "      <td>10001</td>\n",
       "      <td>88</td>\n",
       "      <td>Male</td>\n",
       "      <td>Joint pain;Palpitations</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>61.8</td>\n",
       "      <td>152.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>P098</td>\n",
       "      <td>55401</td>\n",
       "      <td>55</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>Diarrhea;Palpitations;Low-grade fever;Joint pain</td>\n",
       "      <td>Native American</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>68.5</td>\n",
       "      <td>163.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>P099</td>\n",
       "      <td>68102</td>\n",
       "      <td>83</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>Sneezing;Fatigue;Headache</td>\n",
       "      <td>Native American</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>78.7</td>\n",
       "      <td>251.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>P100</td>\n",
       "      <td>10011</td>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>Palpitations;Itching;Abdominal cramps;Low-grad...</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>72.4</td>\n",
       "      <td>244.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID  ZipCode  Age      Gender  \\\n",
       "0       P001    70112   32      Female   \n",
       "1       P002    90002   21      Female   \n",
       "2       P003    20001   46        Male   \n",
       "3       P004    73301   45        Male   \n",
       "4       P005    96813   23  Non-binary   \n",
       "..       ...      ...  ...         ...   \n",
       "95      P096    55414   80      Female   \n",
       "96      P097    10001   88        Male   \n",
       "97      P098    55401   55  Non-binary   \n",
       "98      P099    68102   83  Non-binary   \n",
       "99      P100    10011   18        Male   \n",
       "\n",
       "                                             Symptoms  \\\n",
       "0     Joint pain;Runny nose;Loss of taste;Sore throat   \n",
       "1                    Joint pain;Muscle ache;Dry cough   \n",
       "2   Chest tightness;Sneezing;Fever;Breathing diffi...   \n",
       "3                              Fatigue;Abdominal pain   \n",
       "4   Rash;Sore throat;Loss of smell;Abdominal pain;...   \n",
       "..                                                ...   \n",
       "95                           Blurred vision;Dry cough   \n",
       "96                            Joint pain;Palpitations   \n",
       "97   Diarrhea;Palpitations;Low-grade fever;Joint pain   \n",
       "98                          Sneezing;Fatigue;Headache   \n",
       "99  Palpitations;Itching;Abdominal cramps;Low-grad...   \n",
       "\n",
       "                         Race               Ethnicity  Height_in  Weight_lb  \n",
       "0                       Other      Hispanic or Latino       73.6      229.3  \n",
       "1                       White      Hispanic or Latino       76.8      262.3  \n",
       "2   Black or African American  Not Hispanic or Latino       67.3      187.4  \n",
       "3                       White  Not Hispanic or Latino       67.7      183.0  \n",
       "4            Pacific Islander  Not Hispanic or Latino       74.8      211.6  \n",
       "..                        ...                     ...        ...        ...  \n",
       "95  Black or African American      Hispanic or Latino       66.5      264.6  \n",
       "96                      White  Not Hispanic or Latino       61.8      152.1  \n",
       "97            Native American      Hispanic or Latino       68.5      163.1  \n",
       "98            Native American  Not Hispanic or Latino       78.7      251.3  \n",
       "99  Black or African American  Not Hispanic or Latino       72.4      244.7  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_symptom_df = pd.read_csv('/kaggle/input/patient-symptom-dataset/patient_symptom_data_with_demographics_imperial.csv')\n",
    "patient_symptom_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cca298a",
   "metadata": {
    "papermill": {
     "duration": 0.007389,
     "end_time": "2025-04-20T21:15:25.671501",
     "exception": false,
     "start_time": "2025-04-20T21:15:25.664112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Patient Input and JSON Patient Form\n",
    "\n",
    "I utilized the randint function from the Random library to select a random patient to process information and provide responses for. Then, I utilized JSON Mode through calling the get_json_form method to have the AI mimic filling out a patient form in a simple and abstract way, and to also have the patient/individual demographic information structured in a formalized way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20ec2985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T21:15:25.688026Z",
     "iopub.status.busy": "2025-04-20T21:15:25.687690Z",
     "iopub.status.idle": "2025-04-20T21:15:27.760192Z",
     "shell.execute_reply": "2025-04-20T21:15:27.758785Z"
    },
    "papermill": {
     "duration": 2.083947,
     "end_time": "2025-04-20T21:15:27.763394",
     "exception": false,
     "start_time": "2025-04-20T21:15:25.679447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"zipcode\": 60614,\n",
      "  \"age\": 69,\n",
      "  \"gender\": \"Non-binary\",\n",
      "  \"race\": \"Asian\",\n",
      "  \"ethnicity\": \"Not Hispanic or Latino\",\n",
      "  \"height\": 66.9,\n",
      "  \"weight\": 141.1,\n",
      "  \"symptoms\": [\"Dizziness\", \"Fatigue\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "patient_index = random.randint(0, 99)\n",
    "patient_json_form = get_json_form(patient_symptom_df.iloc[patient_index])\n",
    "print(patient_json_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6dd825",
   "metadata": {
    "papermill": {
     "duration": 0.009659,
     "end_time": "2025-04-20T21:15:27.782673",
     "exception": false,
     "start_time": "2025-04-20T21:15:27.773014",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### AI Request\n",
    "\n",
    "In this first round of few-shot prompting, I utilized few-shot prompting to create a formalized request for the AI model to know what type of patient or individual that the model will be retrieving information for. Few-shot prompting is also used to ensure accuracy and consistency of the format of the request (the model is always clear on what information to extract from the patient and how to process that information into a formalized request). We also used structured output/controlled generation to ensure that the model is consistent in generating the output response as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c9d2014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T21:15:27.800165Z",
     "iopub.status.busy": "2025-04-20T21:15:27.799825Z",
     "iopub.status.idle": "2025-04-20T21:15:28.747434Z",
     "shell.execute_reply": "2025-04-20T21:15:28.746086Z"
    },
    "papermill": {
     "duration": 0.959108,
     "end_time": "2025-04-20T21:15:28.749503",
     "exception": false,
     "start_time": "2025-04-20T21:15:27.790395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"69-year old Not Hispanic or Latino Asian non-binary patient with height of 66.9 inches and weight of 141.1 pounds from zipcode 60614 currently experiencing symptoms of dizziness and fatigue.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = get_general_model_config(0.1, 1, 500)\n",
    "\n",
    "few_shot_prompt = \"\"\"Parse JSON into a string request and only return output: \n",
    "\n",
    "EXAMPLE: \n",
    "{\n",
    "\"zipcode\": 78664, \n",
    "\"age\": 30, \n",
    "\"gender\": \"Female\", \n",
    "\"race\": \"White\", \n",
    "\"ethnicity\": \"Not Hispanic or Latino\", \n",
    "\"height\": 64.6, \n",
    "\"weight\": 130.5, \n",
    "\"symptoms\": [\"Cough\", \"Fever\", \"Sore throat\"]\n",
    "}\n",
    "\"30-year old Not Hispanic or Latino White female patient with height of 64.6 inches and weight of 130.5 pounds from zipcode 78664 currently experiencing symptoms of cough, fever, and sore throat.\"\n",
    "\n",
    "EXAMPLE: \n",
    "{\n",
    "\"zipcode\": 77055, \n",
    "\"age\": 25, \n",
    "\"gender\": \"Non-binary\", \n",
    "\"race\": \"Asian\", \n",
    "\"ethnicity\": \"Not Hispanic or Latino\", \n",
    "\"height\": 60.5, \n",
    "\"weight\": 100.2, \n",
    "\"symptoms\": [\"Joint pain\", \"Loss of smell\"]\n",
    "}\n",
    "\"25-year old Not Hispanic or Latino Asian non-binary patient with height of 60.5 inches and weight of 100.2 pounds from zipcode 77055 currently experiencing symptoms of joint pain and loss of smell.\"\n",
    "\n",
    "EXAMPLE: \n",
    "{\n",
    "\"zipcode\": 78681, \n",
    "\"age\": 15, \n",
    "\"gender\" \"Male\", \n",
    "\"race\": \"Black\", \n",
    "\"ethnicity\": \"Hispanic or Latino\", \n",
    "\"height\": 74.6, \n",
    "\"weight\": 180.5, \n",
    "\"symptoms\": [\"Fatigue\", \"Loss of Vision\", \"Headache\", \"Joint pain\"]\n",
    "}\n",
    "\"15-year old Hispanic or Latino Black male patient with height of 74.6 inches and weight of 180.5 pounds from zipcode 78681 currently experiencing symptoms of fatigue, loss of vision, headache, and joint pain.\"\n",
    "\"\"\"\n",
    "\n",
    "patient_medical_request = few_shot_func(patient_json_form, few_shot_prompt, model_config)\n",
    "print(patient_medical_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884890e6",
   "metadata": {
    "papermill": {
     "duration": 0.00824,
     "end_time": "2025-04-20T21:15:28.765918",
     "exception": false,
     "start_time": "2025-04-20T21:15:28.757678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Potential Diagnosis\n",
    "\n",
    "In this first round of grounding, I utilized grounding to provide a potential but precise diagnosis based on the symptoms and other relevant demographic information, especially zipcode, provided. I am not only utilizing the data that the AI has already been provided to conduct the diagnosis, but also other sources, like the internet as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "584bb2d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T21:15:28.782801Z",
     "iopub.status.busy": "2025-04-20T21:15:28.782443Z",
     "iopub.status.idle": "2025-04-20T21:15:35.317531Z",
     "shell.execute_reply": "2025-04-20T21:15:35.316419Z"
    },
    "papermill": {
     "duration": 6.545639,
     "end_time": "2025-04-20T21:15:35.319466",
     "exception": false,
     "start_time": "2025-04-20T21:15:28.773827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To determine the most likely disease for this patient, let's consider the factors provided: age, ethnicity/race, gender identity, height/weight, location, and symptoms. I will use this information to search for potential conditions.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis_prompt = patient_medical_request + \"What disease are they most likely to experience now? Only return the singular most likely disease, please.\"\n",
    "diagnosis = grounding_func(diagnosis_prompt)\n",
    "Markdown(diagnosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadc5d4d",
   "metadata": {
    "papermill": {
     "duration": 0.007404,
     "end_time": "2025-04-20T21:15:35.334905",
     "exception": false,
     "start_time": "2025-04-20T21:15:35.327501",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*I had to run the grounding process again since after the notebook restarts, the response can be hit-or-miss in terms of accuracy or helpfulness*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f94d016",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T21:15:35.351826Z",
     "iopub.status.busy": "2025-04-20T21:15:35.351467Z",
     "iopub.status.idle": "2025-04-20T21:15:41.997611Z",
     "shell.execute_reply": "2025-04-20T21:15:41.996506Z"
    },
    "papermill": {
     "duration": 6.657099,
     "end_time": "2025-04-20T21:15:41.999785",
     "exception": false,
     "start_time": "2025-04-20T21:15:35.342686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To determine the most likely disease, I need to consider the patient's characteristics (age, ethnicity, gender identity, height, weight), location, and symptoms. I will use this information to search for potential conditions that are more prevalent in similar individuals.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis_prompt = patient_medical_request + \"What disease are they most likely to experience now? Only return the singular most likely disease, please.\"\n",
    "diagnosis = grounding_func(diagnosis_prompt)\n",
    "Markdown(diagnosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74901be",
   "metadata": {
    "papermill": {
     "duration": 0.007522,
     "end_time": "2025-04-20T21:15:42.015741",
     "exception": false,
     "start_time": "2025-04-20T21:15:42.008219",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Patient Zipcode \n",
    "\n",
    "In this second round of few-shot prompting, I utilized few-shot prompting to extract the zipcode of the patient from the JSON form (since at this point, we are using the JSON form to get our data information). Few-shot prompting is utilized to ensure accuracy of the output based on the current format of the JSON form (in this case, a simplified and abstract version of a patient form). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "073daa99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T21:15:42.032779Z",
     "iopub.status.busy": "2025-04-20T21:15:42.032396Z",
     "iopub.status.idle": "2025-04-20T21:15:42.671920Z",
     "shell.execute_reply": "2025-04-20T21:15:42.670730Z"
    },
    "papermill": {
     "duration": 0.65024,
     "end_time": "2025-04-20T21:15:42.673753",
     "exception": false,
     "start_time": "2025-04-20T21:15:42.023513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config_two = get_general_model_config(0, 1, 50)\n",
    "\n",
    "few_shot_prompt_two = \"\"\"Parse JSON to return only the Zipcode: \n",
    "\n",
    "EXAMPLE: \n",
    "{\n",
    "\"zipcode\": 78664, \n",
    "\"age\": 30, \n",
    "\"gender\": \"Female\", \n",
    "\"race\": \"White\", \n",
    "\"ethnicity\": \"Not Hispanic or Latino\", \n",
    "\"height\": 64.6, \n",
    "\"weight\": 130.5, \n",
    "\"symptoms\": [\"Cough\", \"Fever\", \"Sore throat\"]\n",
    "}\n",
    "78664\n",
    "\n",
    "EXAMPLE: \n",
    "{\n",
    "\"zipcode\": 77055, \n",
    "\"age\": 25, \n",
    "\"gender\": \"Non-binary\", \n",
    "\"race\": \"Asian\", \n",
    "\"ethnicity\": \"Not Hispanic or Latino\", \n",
    "\"height\": 60.5, \n",
    "\"weight\": 100.2, \n",
    "\"symptoms\": [\"Joint pain\", \"Loss of smell\"]\n",
    "}\n",
    "77055\n",
    "\n",
    "EXAMPLE: \n",
    "{\n",
    "\"zipcode\": 78681, \n",
    "\"age\": 15, \n",
    "\"gender\" \"Male\", \n",
    "\"race\": \"Black\", \n",
    "\"ethnicity\": \"Hispanic or Latino\", \n",
    "\"height\": 74.6, \n",
    "\"weight\": 180.5, \n",
    "\"symptoms\": [\"Fatigue\", \"Loss of Vision\", \"Headache\", \"Joint pain\"]\n",
    "}\n",
    "78681\n",
    "\"\"\"\n",
    "\n",
    "patient_zipcode = few_shot_func(patient_json_form, few_shot_prompt_two, model_config_two)\n",
    "print(patient_zipcode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c93a48",
   "metadata": {
    "papermill": {
     "duration": 0.007436,
     "end_time": "2025-04-20T21:15:42.689244",
     "exception": false,
     "start_time": "2025-04-20T21:15:42.681808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Nearest Medical Facilities\n",
    "\n",
    "In this second round of grounding, I utilized grounding to provide the nearest appropriate medical facilities for the individual to go to for treatment based on zipcode. We are not only utilizing the data that the AI has already been provided to find the nearest location, but also other sources, like the internet as well. \n",
    "\n",
    "*Note: Would not recommend to run the cell below more than once to get helpful and accurate information*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3c8938d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T21:15:42.706835Z",
     "iopub.status.busy": "2025-04-20T21:15:42.706164Z",
     "iopub.status.idle": "2025-04-20T21:15:47.013975Z",
     "shell.execute_reply": "2025-04-20T21:15:47.012903Z"
    },
    "papermill": {
     "duration": 4.318723,
     "end_time": "2025-04-20T21:15:47.015900",
     "exception": false,
     "start_time": "2025-04-20T21:15:42.697177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, I can help you find some highly-rated medical facilities near the 60614 zip code. Here are a few options, keeping in mind that \"best-rated\" can depend on individual needs and preferences:\n",
       "\n",
       "**Hospitals and Medical Centers:**\n",
       "\n",
       "*   **Advocate Illinois Masonic Medical Center:** While a specific address wasn't immediately available in the search results, this is a major medical center in Chicago with a strong reputation. You can find the exact address on their website.\n",
       "*   **AMITA Health Saint Joseph Hospital Chicago:** Located at 2900 North Lake Shore Drive, Chicago, IL 60657. It is located in the Lakeview neighborhood and has several specialty centers.\n",
       "*   **Northwestern Memorial Hospital:** While not directly *in* 60614, it's a top-ranked hospital in downtown Chicago and easily accessible.\n",
       "*   **The University of Chicago Medical Center:** Located at 5841 South Maryland Avenue, Chicago, IL 60637. A teaching hospital located in the Hyde Park neighborhood of Chicago.\n",
       "*   **One Medical - Lincoln Park:** Located at 1931 N Halsted Street, Chicago, IL 60614. This is a primary care office that also sees all ages.\n",
       "\n",
       "**Other Options:**\n",
       "\n",
       "*   **Innovative Care:** They have multiple locations, including an Urgent Care at 2400 N. Ashland Ave, Chicago, IL 60614, and primary care clinics.\n",
       "*   **AMITA Health Adventist Medical Center Hinsdale:** Located at 120 North Oak Street, Hinsdale, IL 60521.\n",
       "\n",
       "**Important Considerations:**\n",
       "\n",
       "*   **Rankings:** Hospital rankings can vary depending on the source. Some sources to consider include Healthgrades and U.S. News & World Report.\n",
       "*   **Specific Needs:** The \"best\" facility will depend on the specific type of medical care the patient requires. Consider the facility's specialties and services offered.\n",
       "*   **Insurance:** Confirm that the facility accepts the patient's insurance plan.\n",
       "*   **Distance/Accessibility:** While I've focused on facilities near the 60614 zip code, it may be worth considering other top-rated hospitals in the Chicago area, depending on the urgency and specific medical needs.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_prompt = diagnosis + 'Can you get me the nearest best-rated medical facilities with their addresses that can treat the disease for zip code ' + str(patient_zipcode) + '?'\n",
    "recommendations = grounding_func(recommendations_prompt)\n",
    "Markdown(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cc962d",
   "metadata": {
    "papermill": {
     "duration": 0.008492,
     "end_time": "2025-04-20T21:15:47.033643",
     "exception": false,
     "start_time": "2025-04-20T21:15:47.025151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Payment and Insurance Plan Information\n",
    "\n",
    "In this third round of grounding, I utilized grounding to provide payment and insurance plan information for each of the location recommended for treatment. We are not only utilizing the data that the AI has already been provided to retrieve the information, but also other sources, like the internet as well. \n",
    "\n",
    "*Note: Would not recommend to run the cell below more than once to get helpful and accurate information*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "209b1ccb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T21:15:47.051538Z",
     "iopub.status.busy": "2025-04-20T21:15:47.051115Z",
     "iopub.status.idle": "2025-04-20T21:15:55.116897Z",
     "shell.execute_reply": "2025-04-20T21:15:55.115711Z"
    },
    "papermill": {
     "duration": 8.07716,
     "end_time": "2025-04-20T21:15:55.118888",
     "exception": false,
     "start_time": "2025-04-20T21:15:47.041728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To determine the types of payments and insurance plans accepted at each of the listed medical facilities, I will search for that information for each one.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payments_prompt = \"For each of the locations recommended to me: \" + recommendations + \" what types of payments and insurance plans are accepted for patients coming in for treatment?\"\n",
    "payments = grounding_func(payments_prompt)\n",
    "Markdown(payments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093ac941",
   "metadata": {
    "papermill": {
     "duration": 0.007804,
     "end_time": "2025-04-20T21:15:55.135209",
     "exception": false,
     "start_time": "2025-04-20T21:15:55.127405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Limitations and Possible Next Steps\n",
    "\n",
    "While EmergencyZIP AI functions as intended, it is a basic implementation due to time constraints. Some advanced features were not included due to limitations in the development process (e.g., Python input errors). Additionally, grounding-based responses can sometimes be inaccurate, so the AI should not be considered a replacement for professional medical advice. It provides potential diagnoses and recommendations that should be treated as informational rather than authoritative.\n",
    "\n",
    "Future improvements include:\n",
    "\n",
    "* Transitioning the AI into an AI Agent using LangGraph.\n",
    "* Implementing an interactive feature where users input their information, and the AI processes and responds with relevant recommendations.\n",
    "* Developing a UX/UI interface for a more user-friendly experience.\n",
    "* Expanding the JSON form to capture additional information, such as address, health history, sexuality, and income.\n",
    "\n",
    "## Conclusion and Potential Impact \n",
    "I created EmergencyZIP AI to provide individuals with a more individualized and accessible way to understand their symptoms, find appropriate treatment options, and consider the crucial role of zip codes in determining their health. While the current version is basic due to time constraints, it functions as intended, helping users make informed decisions about their healthcare.\n",
    "\n",
    "The goal of this AI is to empower individuals to take charge of their health by providing them with easy access to healthcare resources. Ultimately, I hope EmergencyZIP AI will contribute to improving health outcomes in various regions, one zip code at a time. By helping individuals become more health-conscious and informed, this tool has the potential to make a significant impact on healthcare access and overall well-being."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7088011,
     "sourceId": 11479823,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 47.397481,
   "end_time": "2025-04-20T21:15:55.965770",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-20T21:15:08.568289",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
