{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7168d6e1",
   "metadata": {
    "papermill": {
     "duration": 0.007181,
     "end_time": "2025-04-20T01:07:33.355466",
     "exception": false,
     "start_time": "2025-04-20T01:07:33.348285",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EmergencyZIP AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eeba4f",
   "metadata": {
    "papermill": {
     "duration": 0.006781,
     "end_time": "2025-04-20T01:07:33.369042",
     "exception": false,
     "start_time": "2025-04-20T01:07:33.362261",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Intro\n",
    "\n",
    "As a Data Scientist in Healthcare with 2+ years of industry and work experience, one of the valuable pieces of knowledge that I learned on the job is that Zipcode (Postal Code) is indeed an important factor in determining an individual's health status (thus, wherever the individual lives can determine how healthy or unhealthy an individual can be). Also, healthcare, especially the quality of healthcare, is also an important factor in determining the standard of life of an area as well. However, many people may not be familiar with all the medical facilities that their area may provide or may not know the best one to go to based on what illness or medical condition that they may experience now. Thus, I created the EmergencyZIP AI to help individuals determine the best medical facilities to attend based on the symptoms or conditions that they may be experiencing right now, and to take greater consideration of zipcode/postal code as one of the most important factors of an individual's health status. \n",
    "\n",
    "## Use Case and Solution Approach\n",
    "\n",
    "Individuals may want to know or curious about what current illness or medical condition that they may be facing at the moment, and the nearest and most appropriate medical facilities in their area that can best treat their illness or condition. I created EmergencyZip AI to utilize AI capabilities to not only inform the individual of what illness or condition that they may be facing now, but also inform the individual of the nearest appropriate medical facilities that can best treat the patient with great consideration of the zipcode/postal code as one of the most important factors of an individual's health status. \n",
    "\n",
    "## Process\n",
    "\n",
    "The AI utilizes Structured Output/JSON Mode/Controlled Generation, Few-Shot Prompting, and Grounding to operate. First, it uses JSON Mode to process patient demographic information and structures it to a formalized JSON form (just like filling out a patient form to receive medical care except simplier and more abstract). Then it utilizes Few-Shot Prompting and Structured Output/Controlled Generation to create a formalized request for the AI. Then it utilizes grounding to provide the best and most accurate potential diagnosis for the individual based on the current symptoms/conditions that the individual is facing now. Then using the diagnosis and the current zipcode of the individaul (the AI uses Few-Shot Prompting to extract the zipcode of the individual from the JSON form), the AI finds the nearest and best medical facilities that can treat the individual for the diagnosed illness or condition using grounding. The AI also utilizes grounding to inform the individual payment and insurance plan options that the suggested medical facilities can accept as payment for the treatment. \n",
    "\n",
    "## Innovation/Novelty\n",
    "\n",
    "While the internet is a powerful tool to use to research medical facilities available in the area, with so many search results provided, it can be messy and overwhelming at times to find the best medical facility for treatment of illnesses and medical conditions or even know what actual/potential illness or medical condition that the individual may be facing. With EmergencyZIP AI, the responses provided are tailored and focused only on the individual and the potential illness or medical condition that they are facing now. Also while doctors usually do a great job with diagnosing patients, there could be human bias or error that can be involved in the diagnosis process, so the AI takes in consideration of these potential biases (taking in consideration of patient demographic information) and gives the most accurate diagnosis as possible without being biased. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cdbe2d",
   "metadata": {
    "papermill": {
     "duration": 0.006283,
     "end_time": "2025-04-20T01:07:33.381902",
     "exception": false,
     "start_time": "2025-04-20T01:07:33.375619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Importing Relevant Libraries and Technologies \n",
    "\n",
    "I set up Gemini API to implement my AI (the code also retrieves the API Key from Kaggle Secrets to retrieve the Google API that makes it possible for the AI to work) and imported the Pandas and Random libraries (and other unnamed libraries) to do my test run to check if the AI works as intended or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6415f881",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-20T01:07:33.396523Z",
     "iopub.status.busy": "2025-04-20T01:07:33.396050Z",
     "iopub.status.idle": "2025-04-20T01:07:34.463243Z",
     "shell.execute_reply": "2025-04-20T01:07:34.461912Z"
    },
    "papermill": {
     "duration": 1.076832,
     "end_time": "2025-04-20T01:07:34.465259",
     "exception": false,
     "start_time": "2025-04-20T01:07:33.388427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/patient-symptom-dataset/patient_symptom_data_with_demographics_imperial.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a900a229",
   "metadata": {
    "papermill": {
     "duration": 0.006697,
     "end_time": "2025-04-20T01:07:34.479006",
     "exception": false,
     "start_time": "2025-04-20T01:07:34.472309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The cell below removes any irrelevant libraries that may conflict with the Google Generative AI capabilities and install the Google Gemini Generative AI package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8818e2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T01:07:34.494022Z",
     "iopub.status.busy": "2025-04-20T01:07:34.493437Z",
     "iopub.status.idle": "2025-04-20T01:07:43.456868Z",
     "shell.execute_reply": "2025-04-20T01:07:43.455488Z"
    },
    "papermill": {
     "duration": 8.973726,
     "end_time": "2025-04-20T01:07:43.459300",
     "exception": false,
     "start_time": "2025-04-20T01:07:34.485574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip uninstall -qqy jupyterlab  # Remove unused packages from Kaggle's base image that conflict\n",
    "!pip install -U -q \"google-genai==1.7.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c48206",
   "metadata": {
    "papermill": {
     "duration": 0.006838,
     "end_time": "2025-04-20T01:07:43.473249",
     "exception": false,
     "start_time": "2025-04-20T01:07:43.466411",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Install all relevant libraries for the Google Generative AI capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86a35206",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T01:07:43.489022Z",
     "iopub.status.busy": "2025-04-20T01:07:43.488529Z",
     "iopub.status.idle": "2025-04-20T01:07:44.871987Z",
     "shell.execute_reply": "2025-04-20T01:07:44.870788Z"
    },
    "papermill": {
     "duration": 1.393781,
     "end_time": "2025-04-20T01:07:44.873993",
     "exception": false,
     "start_time": "2025-04-20T01:07:43.480212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "from IPython.display import HTML, Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a24fcdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T01:07:44.889794Z",
     "iopub.status.busy": "2025-04-20T01:07:44.889202Z",
     "iopub.status.idle": "2025-04-20T01:07:45.135969Z",
     "shell.execute_reply": "2025-04-20T01:07:45.134944Z"
    },
    "papermill": {
     "duration": 0.256967,
     "end_time": "2025-04-20T01:07:45.138078",
     "exception": false,
     "start_time": "2025-04-20T01:07:44.881111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "\n",
    "\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "genai.models.Models.generate_content = retry.Retry(\n",
    "    predicate=is_retriable)(genai.models.Models.generate_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5928a2",
   "metadata": {
    "papermill": {
     "duration": 0.006953,
     "end_time": "2025-04-20T01:07:45.152105",
     "exception": false,
     "start_time": "2025-04-20T01:07:45.145152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Retrieve the Google API Key from Kaggle Secrets to make possible for the AI to work in this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da064749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T01:07:45.167419Z",
     "iopub.status.busy": "2025-04-20T01:07:45.166865Z",
     "iopub.status.idle": "2025-04-20T01:07:45.269542Z",
     "shell.execute_reply": "2025-04-20T01:07:45.268602Z"
    },
    "papermill": {
     "duration": 0.112552,
     "end_time": "2025-04-20T01:07:45.271527",
     "exception": false,
     "start_time": "2025-04-20T01:07:45.158975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b68bef7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T01:07:45.286962Z",
     "iopub.status.busy": "2025-04-20T01:07:45.286522Z",
     "iopub.status.idle": "2025-04-20T01:07:45.682810Z",
     "shell.execute_reply": "2025-04-20T01:07:45.681633Z"
    },
    "papermill": {
     "duration": 0.406352,
     "end_time": "2025-04-20T01:07:45.685031",
     "exception": false,
     "start_time": "2025-04-20T01:07:45.278679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764474ef",
   "metadata": {
    "papermill": {
     "duration": 0.006709,
     "end_time": "2025-04-20T01:07:45.698781",
     "exception": false,
     "start_time": "2025-04-20T01:07:45.692072",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generative AI Capabilities Used and Reasoning \n",
    "\n",
    "These are the 3 Generative AI Capabilities Used in this AI and why they are used in this AI: \n",
    "* **Structured Output/JSON Mode/Controlled Generation**: For JSON Mode, I want to somewhat mimic the forms that patients fill out when they are requesting care from a medical facility, but simplier and more abstract. For Structured Output and Controlled Generation, I want my responses to be as accurate and precise as possible where creativity may not be required but accuracy is definitely required to get the best responses as possible.\n",
    "* **Few-Shot Prompting**: First of all, I want to create requests for the AI to know who it is providing information for, but I want the formatting of the requests to be as consistent as possible so that the information does not get muddled up which would make things more difficult for the AI to process and provide information for. Then, I also want to extract the zipcode from the JSON form, but sometimes the AI can hallucinate and return irrelevant or incorrect information, so I want the let the AI know how to return the zipcode correctly.\n",
    "* **Grounding**: This is the central capability of the AI since the AI is responsible for finding all the relevant possible nearest locations to the patient based on postal code/zipcode. Since we are exploring so many zipcodes and it is possible that the AI does not know every zipcode or medical facilities per zipcode, we need to rely on external sources to get the best answers possible. However, since we don't have a document listing out every medical facility per zipcode or all zipcodes, we would need to rely on the internet to give us answers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b6a290",
   "metadata": {
    "papermill": {
     "duration": 0.007367,
     "end_time": "2025-04-20T01:07:45.713528",
     "exception": false,
     "start_time": "2025-04-20T01:07:45.706161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generative AI Capability #1: Structured Output/JSON Mode/Controlled Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23396213",
   "metadata": {
    "papermill": {
     "duration": 0.006629,
     "end_time": "2025-04-20T01:07:45.727015",
     "exception": false,
     "start_time": "2025-04-20T01:07:45.720386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### JSON Mode\n",
    "\n",
    "I created a Python class MedicalPatients to format the JSON form as a simple and abstract patient form, and then I created a get_json_form function that takes in an entry (in this test case, it's a Pandas dataframe entry/row) and structure it to a JSON form as structured in the MedicalPatient class. \n",
    "\n",
    "##### get_json_form function: \n",
    "\n",
    "**Description**: Function takes in an entry (in this case, a Pandas dataframe row) and structures the information provided into a formalized JSON form as structured in the MedicalPatients class. \n",
    "\n",
    "**Input**: ***patient_symptom_entry***: Dataframe Pandas row (for now) of all information needed to be processed as JSON form \n",
    "\n",
    "**Output**: ***json_form***: String of formalized JSON form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc29acfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T01:07:45.742095Z",
     "iopub.status.busy": "2025-04-20T01:07:45.741699Z",
     "iopub.status.idle": "2025-04-20T01:07:45.747873Z",
     "shell.execute_reply": "2025-04-20T01:07:45.746663Z"
    },
    "papermill": {
     "duration": 0.016198,
     "end_time": "2025-04-20T01:07:45.749969",
     "exception": false,
     "start_time": "2025-04-20T01:07:45.733771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import typing_extensions as typing\n",
    "\n",
    "class MedicalPatient(typing.TypedDict): \n",
    "    zipcode: int\n",
    "    age: int\n",
    "    gender: str\n",
    "    race: str\n",
    "    ethnicity: str\n",
    "    height: float\n",
    "    weight: float\n",
    "    symptoms: list[str]\n",
    "\n",
    "def get_json_form(patient_symptom_entry): \n",
    "    entry_str = patient_symptom_entry.to_string()\n",
    "    json_response = client.models.generate_content(\n",
    "        model='gemini-2.0-flash', \n",
    "        config=types.GenerateContentConfig(\n",
    "            temperature=0.1, \n",
    "            response_mime_type=\"application/json\", \n",
    "            response_schema=MedicalPatient\n",
    "        ), \n",
    "        contents=entry_str\n",
    "    )\n",
    "    json_form = json_response.text\n",
    "    return json_form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519e798b",
   "metadata": {
    "papermill": {
     "duration": 0.007196,
     "end_time": "2025-04-20T01:07:45.765211",
     "exception": false,
     "start_time": "2025-04-20T01:07:45.758015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Structured Output/Controlled Generation\n",
    "\n",
    "**Description**: I created the get_general_model_config function to return a Gemini-generated output based on the temperature, top_p, and maximum number of tokens to return inputs.\n",
    "\n",
    "**Input**: \n",
    "* ***temperature***: double that reflects the degree of randomness in selecting tokens for output\n",
    "* ***top_p***: double that is the maximum culmulative probability that the model can reach to select tokens as candidates\n",
    "* ***max_output_tokens***: int that indicates the maximum number of tokens that should be provided and included in the input\n",
    "\n",
    "**Output**: ***str_output***: String of Gemini-generated output based on input parameters provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "050b6307",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T01:07:45.780790Z",
     "iopub.status.busy": "2025-04-20T01:07:45.780375Z",
     "iopub.status.idle": "2025-04-20T01:07:45.784970Z",
     "shell.execute_reply": "2025-04-20T01:07:45.783774Z"
    },
    "papermill": {
     "duration": 0.014623,
     "end_time": "2025-04-20T01:07:45.786904",
     "exception": false,
     "start_time": "2025-04-20T01:07:45.772281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_general_model_config(temperature, top_p, max_output_tokens): \n",
    "    str_output = types.GenerateContentConfig(\n",
    "        temperature=temperature, \n",
    "        top_p=top_p, \n",
    "        max_output_tokens=max_output_tokens\n",
    "    )\n",
    "    return str_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f715b775",
   "metadata": {
    "papermill": {
     "duration": 0.006456,
     "end_time": "2025-04-20T01:07:45.800401",
     "exception": false,
     "start_time": "2025-04-20T01:07:45.793945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generative AI Capability #2: Few-Shot Prompting\n",
    "\n",
    "**Description**: I created the few_shot_func function to implement the few-shot prompting AI capability as code\n",
    "\n",
    "**Input**: \n",
    "* ***model_input***: String that is the input (e.g. a JSON form) that the model takes in consideration of to provide an output response\n",
    "* ***prompt***: String that is the input prompt to provide to the Gemini model to provide a response for; in few-shot prompting, the input prompt provides a few examples with their expected responses to the Gemini model so that the Gemini models knows what to produce for their output format-wise and what their output should look like\n",
    "* ***config***: Python method that is configuration to be used for the Gemini model to produce output (*refer to get_general_model_config as example of Python method to use as possible parameter value*)\n",
    "\n",
    "**Output**: ***str_output***: String of Gemini-generated output based on input parameters provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20d18fa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T01:07:45.815371Z",
     "iopub.status.busy": "2025-04-20T01:07:45.814995Z",
     "iopub.status.idle": "2025-04-20T01:07:45.820144Z",
     "shell.execute_reply": "2025-04-20T01:07:45.818845Z"
    },
    "papermill": {
     "duration": 0.014682,
     "end_time": "2025-04-20T01:07:45.821949",
     "exception": false,
     "start_time": "2025-04-20T01:07:45.807267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def few_shot_func(model_input, prompt, config): \n",
    "    few_shot_response = client.models.generate_content(\n",
    "        model='gemini-2.0-flash', \n",
    "        config=config,\n",
    "        contents=[prompt, model_input]\n",
    "    )\n",
    "    str_response = few_shot_response.text\n",
    "    return str_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbb7251",
   "metadata": {
    "papermill": {
     "duration": 0.006671,
     "end_time": "2025-04-20T01:07:45.835787",
     "exception": false,
     "start_time": "2025-04-20T01:07:45.829116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generative AI Capability #3: Grounding\n",
    "\n",
    "**Description**: I created the grounding_func function to implement the grounding AI capability as code\n",
    "\n",
    "**Input**: ***input_prompt***: String that is the input prompt to provide to the Gemini model to provide a response for\n",
    "\n",
    "**Output**: ***str_response***: String that is the output provided by the Gemini model as response to the input prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3918266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T01:07:45.850818Z",
     "iopub.status.busy": "2025-04-20T01:07:45.850400Z",
     "iopub.status.idle": "2025-04-20T01:07:45.855812Z",
     "shell.execute_reply": "2025-04-20T01:07:45.854570Z"
    },
    "papermill": {
     "duration": 0.01518,
     "end_time": "2025-04-20T01:07:45.857728",
     "exception": false,
     "start_time": "2025-04-20T01:07:45.842548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grounding_func(input_prompt): \n",
    "    config_with_search = types.GenerateContentConfig(\n",
    "        tools=[types.Tool(google_search=types.GoogleSearch())],\n",
    "    )\n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-2.0-flash', \n",
    "        contents=input_prompt, \n",
    "        config=config_with_search,\n",
    "    )\n",
    "    rc = response.candidates[0]\n",
    "    str_response = rc.content.parts[0].text\n",
    "    return str_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af6b82a",
   "metadata": {
    "papermill": {
     "duration": 0.006855,
     "end_time": "2025-04-20T01:07:45.871684",
     "exception": false,
     "start_time": "2025-04-20T01:07:45.864829",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## EmergencyZIP AI Test Run\n",
    "\n",
    "Kaggle Notebooks seem to not work or do well with Python input, so instead, we generated a dataset of patients with relevant demographic information and their symptoms through ChatGPT (so the dataset below is ChatGPT-generated), and then the code picks a random patient to test run the AI to make sure it actually works as intended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4c8a6f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T01:07:45.887827Z",
     "iopub.status.busy": "2025-04-20T01:07:45.887390Z",
     "iopub.status.idle": "2025-04-20T01:07:45.942819Z",
     "shell.execute_reply": "2025-04-20T01:07:45.941797Z"
    },
    "papermill": {
     "duration": 0.065714,
     "end_time": "2025-04-20T01:07:45.944603",
     "exception": false,
     "start_time": "2025-04-20T01:07:45.878889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Race</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Height_in</th>\n",
       "      <th>Weight_lb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>70112</td>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>Joint pain;Runny nose;Loss of taste;Sore throat</td>\n",
       "      <td>Other</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>73.6</td>\n",
       "      <td>229.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>90002</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>Joint pain;Muscle ache;Dry cough</td>\n",
       "      <td>White</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>76.8</td>\n",
       "      <td>262.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P003</td>\n",
       "      <td>20001</td>\n",
       "      <td>46</td>\n",
       "      <td>Male</td>\n",
       "      <td>Chest tightness;Sneezing;Fever;Breathing diffi...</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>67.3</td>\n",
       "      <td>187.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P004</td>\n",
       "      <td>73301</td>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>Fatigue;Abdominal pain</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>67.7</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P005</td>\n",
       "      <td>96813</td>\n",
       "      <td>23</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>Rash;Sore throat;Loss of smell;Abdominal pain;...</td>\n",
       "      <td>Pacific Islander</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>74.8</td>\n",
       "      <td>211.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>P096</td>\n",
       "      <td>55414</td>\n",
       "      <td>80</td>\n",
       "      <td>Female</td>\n",
       "      <td>Blurred vision;Dry cough</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>66.5</td>\n",
       "      <td>264.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>P097</td>\n",
       "      <td>10001</td>\n",
       "      <td>88</td>\n",
       "      <td>Male</td>\n",
       "      <td>Joint pain;Palpitations</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>61.8</td>\n",
       "      <td>152.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>P098</td>\n",
       "      <td>55401</td>\n",
       "      <td>55</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>Diarrhea;Palpitations;Low-grade fever;Joint pain</td>\n",
       "      <td>Native American</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>68.5</td>\n",
       "      <td>163.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>P099</td>\n",
       "      <td>68102</td>\n",
       "      <td>83</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>Sneezing;Fatigue;Headache</td>\n",
       "      <td>Native American</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>78.7</td>\n",
       "      <td>251.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>P100</td>\n",
       "      <td>10011</td>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>Palpitations;Itching;Abdominal cramps;Low-grad...</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>72.4</td>\n",
       "      <td>244.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID  ZipCode  Age      Gender  \\\n",
       "0       P001    70112   32      Female   \n",
       "1       P002    90002   21      Female   \n",
       "2       P003    20001   46        Male   \n",
       "3       P004    73301   45        Male   \n",
       "4       P005    96813   23  Non-binary   \n",
       "..       ...      ...  ...         ...   \n",
       "95      P096    55414   80      Female   \n",
       "96      P097    10001   88        Male   \n",
       "97      P098    55401   55  Non-binary   \n",
       "98      P099    68102   83  Non-binary   \n",
       "99      P100    10011   18        Male   \n",
       "\n",
       "                                             Symptoms  \\\n",
       "0     Joint pain;Runny nose;Loss of taste;Sore throat   \n",
       "1                    Joint pain;Muscle ache;Dry cough   \n",
       "2   Chest tightness;Sneezing;Fever;Breathing diffi...   \n",
       "3                              Fatigue;Abdominal pain   \n",
       "4   Rash;Sore throat;Loss of smell;Abdominal pain;...   \n",
       "..                                                ...   \n",
       "95                           Blurred vision;Dry cough   \n",
       "96                            Joint pain;Palpitations   \n",
       "97   Diarrhea;Palpitations;Low-grade fever;Joint pain   \n",
       "98                          Sneezing;Fatigue;Headache   \n",
       "99  Palpitations;Itching;Abdominal cramps;Low-grad...   \n",
       "\n",
       "                         Race               Ethnicity  Height_in  Weight_lb  \n",
       "0                       Other      Hispanic or Latino       73.6      229.3  \n",
       "1                       White      Hispanic or Latino       76.8      262.3  \n",
       "2   Black or African American  Not Hispanic or Latino       67.3      187.4  \n",
       "3                       White  Not Hispanic or Latino       67.7      183.0  \n",
       "4            Pacific Islander  Not Hispanic or Latino       74.8      211.6  \n",
       "..                        ...                     ...        ...        ...  \n",
       "95  Black or African American      Hispanic or Latino       66.5      264.6  \n",
       "96                      White  Not Hispanic or Latino       61.8      152.1  \n",
       "97            Native American      Hispanic or Latino       68.5      163.1  \n",
       "98            Native American  Not Hispanic or Latino       78.7      251.3  \n",
       "99  Black or African American  Not Hispanic or Latino       72.4      244.7  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_symptom_df = pd.read_csv('/kaggle/input/patient-symptom-dataset/patient_symptom_data_with_demographics_imperial.csv')\n",
    "patient_symptom_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a5b499",
   "metadata": {
    "papermill": {
     "duration": 0.006953,
     "end_time": "2025-04-20T01:07:45.958945",
     "exception": false,
     "start_time": "2025-04-20T01:07:45.951992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We utilize the randint function from the Random library to select a random patient to process information and provide responses for. We then utilize JSON Mode through calling the get_json_form method to have the AI mimic filling out a patient form in a simple and abstract way, and to also have the patient/individual demographic information structured in a formalized way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7f9fe94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T01:07:45.975280Z",
     "iopub.status.busy": "2025-04-20T01:07:45.974768Z",
     "iopub.status.idle": "2025-04-20T01:07:47.086521Z",
     "shell.execute_reply": "2025-04-20T01:07:47.085239Z"
    },
    "papermill": {
     "duration": 1.122527,
     "end_time": "2025-04-20T01:07:47.088692",
     "exception": false,
     "start_time": "2025-04-20T01:07:45.966165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"zipcode\": 90002,\n",
      "  \"age\": 51,\n",
      "  \"gender\": \"Male\",\n",
      "  \"race\": \"Native American\",\n",
      "  \"ethnicity\": \"Not Hispanic or Latino\",\n",
      "  \"height\": 78.0,\n",
      "  \"weight\": 227.1,\n",
      "  \"symptoms\": [\n",
      "    \"Chest pain\",\n",
      "    \"Dizziness\",\n",
      "    \"Vomiting\",\n",
      "    \"Breathing difficulties\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "patient_index = random.randint(0, 99)\n",
    "patient_json_form = get_json_form(patient_symptom_df.iloc[patient_index])\n",
    "print(patient_json_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e40523",
   "metadata": {
    "papermill": {
     "duration": 0.007125,
     "end_time": "2025-04-20T01:07:47.103896",
     "exception": false,
     "start_time": "2025-04-20T01:07:47.096771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this first round of few-shot prompting, we utilize few-shot prompting to create a formalized request for the AI model to know what type of patient or individual that the model will be retrieving information for. Few-shot prompting is also used to ensure accuracy and consistency of the format of the request (the model is always clear on what information to extract from the patient and how to process that information into a formalized request). We also used structured output/controlled generation to ensure that the model is consistent in generating the output response as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfa29962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T01:07:47.120747Z",
     "iopub.status.busy": "2025-04-20T01:07:47.120353Z",
     "iopub.status.idle": "2025-04-20T01:07:47.671556Z",
     "shell.execute_reply": "2025-04-20T01:07:47.670249Z"
    },
    "papermill": {
     "duration": 0.561962,
     "end_time": "2025-04-20T01:07:47.673282",
     "exception": false,
     "start_time": "2025-04-20T01:07:47.111320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"51-year old Not Hispanic or Latino Native American male patient with height of 78.0 inches and weight of 227.1 pounds from zipcode 90002 currently experiencing symptoms of chest pain, dizziness, vomiting, and breathing difficulties.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = get_general_model_config(0.1, 1, 500)\n",
    "\n",
    "few_shot_prompt = \"\"\"Parse JSON into a string request and only return output: \n",
    "\n",
    "EXAMPLE: \n",
    "{\n",
    "\"zipcode\": 78664, \n",
    "\"age\": 30, \n",
    "\"gender\": \"Female\", \n",
    "\"race\": \"White\", \n",
    "\"ethnicity\": \"Not Hispanic or Latino\", \n",
    "\"height\": 64.6, \n",
    "\"weight\": 130.5, \n",
    "\"symptoms\": [\"Cough\", \"Fever\", \"Sore throat\"]\n",
    "}\n",
    "\"30-year old Not Hispanic or Latino White female patient with height of 64.6 inches and weight of 130.5 pounds from zipcode 78664 currently experiencing symptoms of cough, fever, and sore throat.\"\n",
    "\n",
    "EXAMPLE: \n",
    "{\n",
    "\"zipcode\": 77055, \n",
    "\"age\": 25, \n",
    "\"gender\": \"Non-binary\", \n",
    "\"race\": \"Asian\", \n",
    "\"ethnicity\": \"Not Hispanic or Latino\", \n",
    "\"height\": 60.5, \n",
    "\"weight\": 100.2, \n",
    "\"symptoms\": [\"Joint pain\", \"Loss of smell\"]\n",
    "}\n",
    "\"25-year old Not Hispanic or Latino Asian non-binary patient with height of 60.5 inches and weight of 100.2 pounds from zipcode 77055 currently experiencing symptoms of joint pain and loss of smell.\"\n",
    "\n",
    "EXAMPLE: \n",
    "{\n",
    "\"zipcode\": 78681, \n",
    "\"age\": 15, \n",
    "\"gender\" \"Male\", \n",
    "\"race\": \"Black\", \n",
    "\"ethnicity\": \"Hispanic or Latino\", \n",
    "\"height\": 74.6, \n",
    "\"weight\": 180.5, \n",
    "\"symptoms\": [\"Fatigue\", \"Loss of Vision\", \"Headache\", \"Joint pain\"]\n",
    "}\n",
    "\"15-year old Hispanic or Latino Black male patient with height of 74.6 inches and weight of 180.5 pounds from zipcode 78681 currently experiencing symptoms of fatigue, loss of vision, headache, and joint pain.\"\n",
    "\"\"\"\n",
    "\n",
    "patient_medical_request = few_shot_func(patient_json_form, few_shot_prompt, model_config)\n",
    "print(patient_medical_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bdc958",
   "metadata": {
    "papermill": {
     "duration": 0.007193,
     "end_time": "2025-04-20T01:07:47.688329",
     "exception": false,
     "start_time": "2025-04-20T01:07:47.681136",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this first round of grounding, we utilize grounding to provide a potential but precise diagnosis based on the symptoms and other relevant demographic information, especially zipcode, provided. We are not only utilizing the data that the AI has already been provided to conduct the diagnosis, but also other sources, like the internet as well. \n",
    "\n",
    "*Note: If you have restarted the Kaggle notebook, you may have to run the cell below twice to actually get a helpful and accurate answer.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eebc633f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T01:07:47.704500Z",
     "iopub.status.busy": "2025-04-20T01:07:47.704073Z",
     "iopub.status.idle": "2025-04-20T01:07:51.914151Z",
     "shell.execute_reply": "2025-04-20T01:07:51.913078Z"
    },
    "papermill": {
     "duration": 4.220129,
     "end_time": "2025-04-20T01:07:51.915969",
     "exception": false,
     "start_time": "2025-04-20T01:07:47.695840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To determine the most likely disease, I need to consider the patient's characteristics (age, ethnicity, sex, height, weight), location (zip code), and symptoms. Let's use search queries to narrow down potential conditions.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis_prompt = patient_medical_request + \"What disease are they most likely to experience now? Only return the singular most likely disease, please.\"\n",
    "diagnosis = grounding_func(diagnosis_prompt)\n",
    "Markdown(diagnosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af674e7",
   "metadata": {
    "papermill": {
     "duration": 0.007388,
     "end_time": "2025-04-20T01:07:51.931217",
     "exception": false,
     "start_time": "2025-04-20T01:07:51.923829",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this second round of few-shot prompting, we utilize few-shot prompting to extract the zipcode of the patient from the JSON form (since at this point, we are using the JSON form to get our data information). Few-shot prompting is utilized to ensure accuracy of the output based on the current format of the JSON form (in this case, a simplified and abstract version of a patient form). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e19aa381",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T01:07:51.948115Z",
     "iopub.status.busy": "2025-04-20T01:07:51.947768Z",
     "iopub.status.idle": "2025-04-20T01:07:52.344545Z",
     "shell.execute_reply": "2025-04-20T01:07:52.343281Z"
    },
    "papermill": {
     "duration": 0.40806,
     "end_time": "2025-04-20T01:07:52.346858",
     "exception": false,
     "start_time": "2025-04-20T01:07:51.938798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config_two = get_general_model_config(0, 1, 50)\n",
    "\n",
    "few_shot_prompt_two = \"\"\"Parse JSON to return only the Zipcode: \n",
    "\n",
    "EXAMPLE: \n",
    "{\n",
    "\"zipcode\": 78664, \n",
    "\"age\": 30, \n",
    "\"gender\": \"Female\", \n",
    "\"race\": \"White\", \n",
    "\"ethnicity\": \"Not Hispanic or Latino\", \n",
    "\"height\": 64.6, \n",
    "\"weight\": 130.5, \n",
    "\"symptoms\": [\"Cough\", \"Fever\", \"Sore throat\"]\n",
    "}\n",
    "78664\n",
    "\n",
    "EXAMPLE: \n",
    "{\n",
    "\"zipcode\": 77055, \n",
    "\"age\": 25, \n",
    "\"gender\": \"Non-binary\", \n",
    "\"race\": \"Asian\", \n",
    "\"ethnicity\": \"Not Hispanic or Latino\", \n",
    "\"height\": 60.5, \n",
    "\"weight\": 100.2, \n",
    "\"symptoms\": [\"Joint pain\", \"Loss of smell\"]\n",
    "}\n",
    "77055\n",
    "\n",
    "EXAMPLE: \n",
    "{\n",
    "\"zipcode\": 78681, \n",
    "\"age\": 15, \n",
    "\"gender\" \"Male\", \n",
    "\"race\": \"Black\", \n",
    "\"ethnicity\": \"Hispanic or Latino\", \n",
    "\"height\": 74.6, \n",
    "\"weight\": 180.5, \n",
    "\"symptoms\": [\"Fatigue\", \"Loss of Vision\", \"Headache\", \"Joint pain\"]\n",
    "}\n",
    "78681\n",
    "\"\"\"\n",
    "\n",
    "patient_zipcode = few_shot_func(patient_json_form, few_shot_prompt_two, model_config_two)\n",
    "print(patient_zipcode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4b2178",
   "metadata": {
    "papermill": {
     "duration": 0.007557,
     "end_time": "2025-04-20T01:07:52.367965",
     "exception": false,
     "start_time": "2025-04-20T01:07:52.360408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this second round of grounding, we utilize grounding to provide the nearest appropriate medical facilities for the individual to go to for treatment based on zipcode. We are not only utilizing the data that the AI has already been provided to find the nearest location, but also other sources, like the internet as well. \n",
    "\n",
    "*Note: Would not recommend to run the cell below more than once to get helpful and accurate information*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "680045cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T01:07:52.384799Z",
     "iopub.status.busy": "2025-04-20T01:07:52.384367Z",
     "iopub.status.idle": "2025-04-20T01:07:55.981580Z",
     "shell.execute_reply": "2025-04-20T01:07:55.980466Z"
    },
    "papermill": {
     "duration": 3.608152,
     "end_time": "2025-04-20T01:07:55.983705",
     "exception": false,
     "start_time": "2025-04-20T01:07:52.375553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, I will search for the highest-rated medical facilities near the 90002 zip code. Here are some options based on my search:\n",
       "\n",
       "*   **Watts Medical Offices - Kaiser Permanente:** Located within the 90002 zip code at 1465 E 103rd St, Los Angeles, CA 90002.\n",
       "*   **Watts Healthcare Corporation:** Located at 10300 Compton Ave, Los Angeles, CA 90002.\n",
       "\n",
       "Other highly-rated hospitals within a few miles of the 90002 zip code include:\n",
       "\n",
       "*   **PIH Health Good Samaritan Hospital:** Located at 1225 Wilshire Blvd, Los Angeles, CA 90017.\n",
       "*   **Adventist Health White Memorial:** Located at 1720 E Cesar E Chavez Ave, Los Angeles, CA 90033.\n",
       "*   **California Hospital Medical Center:** Located at 1401 South Grand Avenue, Los Angeles, CA 90015.\n",
       "*   **UCLA Medical Center:** Located at 757 Westwood Plaza, Los Angeles, CA 90095. Nationally ranked and the #1 hospital in Los Angeles and California.\n",
       "*   **Cedars-Sinai Medical Center:** Located at 8700 Beverly Boulevard, Los Angeles, CA 90048. Also nationally ranked.\n",
       "*   **Keck Medical Center of USC:** Located in Los Angeles.\n",
       "\n",
       "It's worth noting that hospital ratings can vary based on the source (e.g., U.S. News & World Report, Centers for Medicare & Medicaid Services (CMS)).\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_prompt = diagnosis + 'Can you get me the nearest best-rated medical facilities with their addresses that can treat the disease for zip code ' + str(patient_zipcode) + '?'\n",
    "recommendations = grounding_func(recommendations_prompt)\n",
    "Markdown(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b78c36e",
   "metadata": {
    "papermill": {
     "duration": 0.00747,
     "end_time": "2025-04-20T01:07:55.999225",
     "exception": false,
     "start_time": "2025-04-20T01:07:55.991755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this third round of grounding, we utilize grounding to provide payment and insurance plan information for each of the location recommended for treatment. We are not only utilizing the data that the AI has already been provided to retrieve the information, but also other sources, like the internet as well. \n",
    "\n",
    "*Note: Would not recommend to run the cell below more than once to get helpful and accurate information*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efc85abd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T01:07:56.017555Z",
     "iopub.status.busy": "2025-04-20T01:07:56.017134Z",
     "iopub.status.idle": "2025-04-20T01:08:02.234977Z",
     "shell.execute_reply": "2025-04-20T01:08:02.233956Z"
    },
    "papermill": {
     "duration": 6.228934,
     "end_time": "2025-04-20T01:08:02.236878",
     "exception": false,
     "start_time": "2025-04-20T01:07:56.007944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "It's important to contact each facility directly or check their website to confirm the most up-to-date information on accepted insurance plans and payment options. Insurance plans and coverage can change, so direct confirmation is always best.\n",
       "\n",
       "Here's a summary of the payment and insurance information for each facility, based on the search results:\n",
       "\n",
       "*   **Watts Medical Offices - Kaiser Permanente:**\n",
       "    *   Kaiser Permanente plans are accepted.\n",
       "    *   They follow the same quality review processes for practitioners and facilities in Marketplace Silver-tier plans as they do for all other Kaiser Foundation Health Plan products and lines of business.\n",
       "    *   Contact them directly to confirm specific plan coverage.\n",
       "\n",
       "*   **Watts Healthcare Corporation:**\n",
       "    *   Accepts most insurance plans, including Medi-Cal Managed Care options, California Health and Wellness, and Anthem Blue Cross Partnership Plans, Medicare, and private pay.\n",
       "    *   Offers a sliding fee discount program for those who are uninsured, underinsured, ineligible for government programs, or otherwise unable to pay.\n",
       "    *   They have certified enrollment counselors to help with applying for Medicaid, Medicare, or insurance plans through California's insurance marketplace.\n",
       "    *   All insurances are accepted. Sliding scale is available for those without insurance.\n",
       "\n",
       "*   **PIH Health Good Samaritan Hospital:**\n",
       "    *   Accepts Aetna, Affiliated Health Funds, Anthem Blue Cross, Beech Street Network, Blue Shield, Centivo, Cigna, First Health Network / Coventry Health Care, and Health Net.\n",
       "    *   For HMO plans, patients need to select a PIH Health Physician as their Primary Care Physician.\n",
       "\n",
       "*   **Adventist Health White Memorial:**\n",
       "    *   Accepts most major health plans, including Medi-Cal and Medicare.\n",
       "    *   They can assist with enrolling patients into a plan that fits their needs.\n",
       "    *   Accepts L.A. Care, Health Net, Blue Shield Promise, Anthem, and Molina for Managed Care Medi-Cal.\n",
       "    *   Offers financial assistance and payment options for those who are uninsured or need additional resources.\n",
       "\n",
       "*   **California Hospital Medical Center:**\n",
       "    *   It's advisable to contact the hospital directly or visit their website to get the most accurate and up-to-date information on accepted insurance plans and payment options.\n",
       "\n",
       "*   **UCLA Medical Center:**\n",
       "    *   Accepts Medicare-assignment and private indemnity insurance.\n",
       "    *   Participates in over 100 local and national managed care networks.\n",
       "    *   It's best to call 1-800-UCLA-MD1 to confirm whether your specific insurance is accepted.\n",
       "    *   They accept HMOs, PPOs, Medicare, Medicare Advantage and Medi-Cal.\n",
       "\n",
       "*   **Cedars-Sinai Medical Center:**\n",
       "    *   Contracted with over 100 types of insurance plans, including private insurance, HMO, PPO, POS, EPO, Medicare, and Medi-Cal.\n",
       "    *   If a plan is not listed, it is recommended to contact the health insurance provider directly.\n",
       "\n",
       "*   **Keck Medical Center of USC:**\n",
       "    *   Accepts Medicare-assignment and private insurance.\n",
       "    *   Works with many local and national managed care networks.\n",
       "    *   It's recommended to call (800) USC-CARE to check if your insurance is accepted.\n",
       "    *   They work closely with patients and their insurance company to create a seamless payment process.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payments_prompt = \"For each of the locations recommended to me: \" + recommendations + \" what types of payments and insurance plans are accepted for patients coming in for treatment?\"\n",
    "payments = grounding_func(payments_prompt)\n",
    "Markdown(payments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0168a56",
   "metadata": {
    "papermill": {
     "duration": 0.007462,
     "end_time": "2025-04-20T01:08:02.252439",
     "exception": false,
     "start_time": "2025-04-20T01:08:02.244977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Limitations and Possible Next Steps\n",
    "\n",
    "While the AI works as intended, this is a very basic setup/implementation of the AI (to be honest, we were short on time to implement the more advanced features/capabilities to make the AI run more efficiently and impressively). Thus, possible next steps/future directions are as follows: \n",
    "\n",
    "## Conclusion and Potential Impact \n",
    "\n",
    "We intend for the AI to empower individuals to make informed decisions that is best for their health and to know more and better of the variety of medical options provided for them to take care of their health, especially in illness and bad health (thus, we hope that with this AI, individuals take the initiative to become healthier and more health-conscious individuals). We also hope that the AI can help improve health outcomes for every zipcode/postal code as possible. "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7088011,
     "sourceId": 11479823,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33.333594,
   "end_time": "2025-04-20T01:08:03.081760",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-20T01:07:29.748166",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
